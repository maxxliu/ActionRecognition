{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"frame_collection.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"r7V6svPukWzi","colab_type":"code","outputId":"31e22800-dfcd-41b7-9d45-6ccc4f66894f","executionInfo":{"status":"ok","timestamp":1544672492433,"user_tz":360,"elapsed":1375,"user":{"displayName":"Max Liu","photoUrl":"","userId":"00090862810546371156"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"cell_type":"code","source":["import tensorflow as tf\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import random\n","from frame_collection import *\n","\n","# loading data from google drive\n","# NOTE: force remount takes some time\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","# data folder location\n","HMDB_DATA = 'drive/My Drive/Computer Vision/HMDB/hmdb51_org/'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"iAyy_yzyW7RQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1772},"outputId":"9a70a81f-44d4-48f8-be77-9ec2e8745a93","executionInfo":{"status":"ok","timestamp":1544676908482,"user_tz":360,"elapsed":4413826,"user":{"displayName":"Max Liu","photoUrl":"","userId":"00090862810546371156"}}},"cell_type":"code","source":["# collect_frames_from_video(num_frames=5, frame_processing=flatten_frames, force_resize=(128, 128))\n","collect_frames_from_video(num_frames=14, frame_processing=flatten_frames, force_resize=(125, 125))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Getting video file paths...\n","Found 6802 files\n","Working on collecting frames...\n","Working on smile\n","\tDone with 1/51\n","Working on flic_flac\n","\tDone with 2/51\n","Working on drink\n","\tDone with 3/51\n","Working on talk\n","\tDone with 4/51\n","Working on situp\n","\tDone with 5/51\n","Working on fall_floor\n","\tDone with 6/51\n","Working on handstand\n","\tDone with 7/51\n","Working on laugh\n","\tDone with 8/51\n","Working on pick\n","\tDone with 9/51\n","Working on dribble\n","\tDone with 10/51\n","Working on shoot_gun\n","\tDone with 11/51\n","Working on shoot_ball\n","\tDone with 12/51\n","Working on punch\n","\tDone with 13/51\n","Working on wave\n","\tDone with 14/51\n","Working on catch\n","\tDone with 15/51\n","Working on kick_ball\n","\tDone with 16/51\n","Working on run\n","\tDone with 17/51\n","Working on stand\n","\tDone with 18/51\n","Working on chew\n","\tDone with 19/51\n","Working on draw_sword\n","\tDone with 20/51\n","Working on somersault\n","\tDone with 21/51\n","Working on cartwheel\n","\tDone with 22/51\n","Working on fencing\n","\tDone with 23/51\n","Working on pullup\n","\tDone with 24/51\n","Working on shake_hands\n","\tDone with 25/51\n","Working on climb_stairs\n","\tDone with 26/51\n","Working on clap\n","\tDone with 27/51\n","Working on eat\n","\tDone with 28/51\n","Working on pour\n","\tDone with 29/51\n","Working on push\n","\tDone with 30/51\n","Working on shoot_bow\n","\tDone with 31/51\n","Working on ride_horse\n","\tDone with 32/51\n","Working on kiss\n","\tDone with 33/51\n","Working on dive\n","\tDone with 34/51\n","Working on hug\n","\tDone with 35/51\n","Working on jump\n","\tDone with 36/51\n","Working on sit\n","\tDone with 37/51\n","Working on throw\n","\tDone with 38/51\n","Working on turn\n","\tDone with 39/51\n","Working on pushup\n","\tDone with 40/51\n","Working on brush_hair\n","\tDone with 41/51\n","Working on kick\n","\tDone with 42/51\n","Working on sword_exercise\n","\tDone with 43/51\n","Working on smoke\n","\tDone with 44/51\n","Working on sword\n","\tDone with 45/51\n","Working on hit\n","\tDone with 46/51\n","Working on golf\n","\tDone with 47/51\n","Working on swing_baseball\n","\tDone with 48/51\n","Working on climb\n","\tDone with 49/51\n","Working on walk\n","\tDone with 50/51\n","Working on ride_bike\n","\tDone with 51/51\n","Resizing frames...\n","Processing frames...\n","Done\n"],"name":"stdout"}]},{"metadata":{"id":"piAiarRVlL9I","colab_type":"code","colab":{}},"cell_type":"code","source":["# # find all of the videos and labels\n","# file_count = 0\n","# video_files = {}\n","# for label in os.listdir(HMDB_DATA):\n","#   if '.' in label:\n","#     # this is not a real directory\n","#     pass\n","#   else:\n","#     video_files[label] = []\n","#     new_dir = HMDB_DATA + label + '/'\n","#     for video in os.listdir(new_dir):\n","#       video_files[label].append(new_dir + video)\n","#       file_count += 1\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"G3SO0PXIqe5l","colab_type":"code","colab":{}},"cell_type":"code","source":["# # select x many frames from each video\n","# max_x_dim = 0\n","# max_y_dim = 0\n","# num_frames = 1\n","# frame_data = []\n","# labels = []\n","# count = 0\n","# for label in video_files.keys():\n","#   print('Working on ' + label)\n","#   for video in video_files[label]:\n","#     # select x many random frames from the video\n","#     # NOTE: we may switch to using many consecutive frames\n","#     cap = cv2.VideoCapture(video)\n","#     nframe = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","#     for i in range(num_frames):\n","# #       cap.set(cv2.CAP_PROP_POS_FRAMES, int(nframe * random.random()) % nframe)\n","#       cap.set(cv2.CAP_PROP_POS_FRAMES, int(nframe / 2))\n","#       ret, frame = cap.read()\n","#       frameGscl = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n","#       # normalize\n","#       frameGscl = frameGscl / 255\n","#       # need to perform some checks on ret and frameGscl\n","#       # + check frame dimensions are as expected\n","#       assert frameGscl.ndim == 2, 'ERROR: frame has wrong dimensions'\n","#       # + check that ret is true\n","#       assert ret, 'ERROR: returned no frame'\n","#       # after checks complete add frame and label\n","#       labels.append(label)\n","#       frame_data.append(frameGscl)\n","#       # keep track of largest dimensions to pad every image\n","#       max_x_dim = max(max_x_dim, frameGscl.shape[0])\n","#       max_y_dim = max(max_y_dim, frameGscl.shape[1])\n","#   count += 1\n","#   print('\\tDone with %d' % count)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xgqj4ZXVAtum","colab_type":"code","colab":{}},"cell_type":"code","source":["# # resize all of the images by padding to the largest dimensions\n","# for i, frame in enumerate(frame_data):\n","#   frame_data[i] = cv2.resize(frame, (max_y_dim, max_x_dim))\n","#   frame_data[i] = frame_data[i].astype(np.float16)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zI6e5z69cwIJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# # save labels and frames\n","# labels_file = 'labels_single_frame.npy'\n","# np.save('drive/My Drive/Computer Vision/HMDB/saved_training/' + labels_file, labels)\n","# frame_data_file = 'frame_data_single_frame.npy'\n","# np.save('drive/My Drive/Computer Vision/HMDB/saved_training/' + frame_data_file, frame_data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-2u-uffH3UlR","colab_type":"code","colab":{}},"cell_type":"code","source":["# ############################\n","# # change frames to be flat #\n","# ############################\n","\n","# frame_data_file = 'frame_data_single_frame.npy'\n","# # load the frames and flatten all of them\n","# frames = np.load('drive/My Drive/Computer Vision/HMDB/saved_training/' + frame_data_file).astype(np.float16)\n","# flattened = np.zeros((len(frames), 142080)).astype(np.float16)\n","# for i, frame in enumerate(frames):\n","#   flattened[i] = frame.flatten()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LXvSKiix3U90","colab_type":"code","colab":{}},"cell_type":"code","source":["# # save the flattened files\n","# flattened_data_file = 'frame_data_single_frame_flattened.npy'\n","# np.save('drive/My Drive/Computer Vision/HMDB/saved_training/' + flattened_data_file, flattened)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6EzUNkFo8QJg","colab_type":"code","colab":{}},"cell_type":"code","source":["########################################\n","# change frames to be smaller and flat #\n","########################################"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FSdBpaiHGjF8","colab_type":"code","colab":{}},"cell_type":"code","source":["# frame_data_file = 'frame_data_single_frame.npy'\n","# # load the frames and flatten all of them\n","# frames = np.load('drive/My Drive/Computer Vision/HMDB/saved_training/' + frame_data_file).astype(np.float16)\n","# small_flat = np.zeros((len(frames), 10000)).astype(np.float16)\n","# for i, frame in enumerate(frames):\n","#   frame = cv2.resize(frame.astype(np.float64), (100, 100))\n","#   small_flat[i] = frame.flatten().astype(np.float16)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zUEd1OqrGjLJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# # save the flattened files\n","# small_flattened_data_file = 'frame_data_single_frame_flattened_small.npy'\n","# np.save('drive/My Drive/Computer Vision/HMDB/saved_training/' + small_flattened_data_file, small_flat)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZxG5fbF1GjQX","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}