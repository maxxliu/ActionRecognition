{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"rfdyQQiOCTZU","colab_type":"code","outputId":"075a6a74-9313-4b95-bc63-82b30476c421","executionInfo":{"status":"ok","timestamp":1544644383472,"user_tz":360,"elapsed":1657,"user":{"displayName":"Anand Kannappan","photoUrl":"https://lh5.googleusercontent.com/-RBaeYAFRI9g/AAAAAAAAAAI/AAAAAAAAAHA/dDIr1dAXiyM/s64/photo.jpg","userId":"04884028647086034831"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","import random\n","import time\n","from sklearn.model_selection import train_test_split\n","%matplotlib inline\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"xdVfIGosivVx","colab_type":"code","colab":{}},"cell_type":"code","source":["# Convert classes to indicator vectors\n","def one_hot(values,n_values=51):\n","    n_v = np.maximum(n_values, np.max(values) + 1)\n","    oh = np.eye(n_v)[values]\n","    return oh"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V7Og_j1p3hKs","colab_type":"code","colab":{}},"cell_type":"code","source":["frame_data = np.float16(np.load('drive/My Drive/Computer Vision/HMDB/saved_training/frame_data_5_frame_flat_OPTFLOW_1544641757.npy'))\n","labels = np.load('drive/My Drive/Computer Vision/HMDB/saved_training/labels_5_frame_OPTFLOW_1544641757.npy')\n","\n","n = 0\n","class_labels = {}\n","new_labels = []\n","for l in labels:\n","  if l in class_labels:\n","    new_labels.append(class_labels[l])\n","  else:\n","    class_labels[l] = n\n","    new_labels.append(n)\n","    n += 1\n","labels = one_hot(np.array(new_labels))\n","\n","train_data, test_data, train_labels, test_labels = train_test_split(frame_data, labels, test_size=0.1, random_state=102)\n","val_data = train_data[int(0.9 * len(train_data)):len(train_data)]\n","val_labels = np.int16(train_labels[int(0.9 * len(train_data)):len(train_labels)])\n","train_data = train_data[0:int(0.9 * len(train_data))]\n","train_labels = np.int16(train_labels[0:int(0.9 * len(train_labels))])\n","\n","# train_data = frame_data[0:int(0.7 * len(frame_data))]\n","# train_labels = one_hot(np.int16(labels[0:int(0.7 * len(frame_data))]))\n","# val_data = frame_data[int(0.7 * len(frame_data)):int(0.85 * len(frame_data))]\n","# val_labels = one_hot(np.int16(labels[int(0.7 * len(frame_data)):int(0.85 * len(frame_data))]))\n","# test_data = frame_data[int(0.85 * len(frame_data)):len(frame_data)]\n","# test_labels = one_hot(np.int16(labels[int(0.85 * len(frame_data)):len(frame_data)]))\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pm50uSK_aHF7","colab_type":"code","colab":{}},"cell_type":"code","source":["def conv_relu_layer(input, filter_size=[3,3], num_features=[1]):\n","    # Get number of input features from input and add to shape of new layer\n","    shape = filter_size + [input.get_shape().as_list()[-1], num_features]\n","    W = tf.get_variable('W',shape=shape) # Default initialization is Glorot\n","    b = tf.get_variable('b',shape=[num_features],initializer=tf.zeros_initializer) \n","    conv = tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding='SAME')\n","    relu = tf.nn.relu(conv + b)\n","    return(relu)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hVLimkQFcJXd","colab_type":"code","colab":{}},"cell_type":"code","source":["def fully_connected_layer(input,num_features):\n","    # Make sure input is flattened\n","    flat_dim = np.int32(np.array(input.get_shape().as_list())[1:].prod())\n","    input_flattened = tf.reshape(input, shape=[-1,flat_dim])\n","    shape = [flat_dim,num_features]\n","    W_fc = tf.get_variable('W', shape=shape) \n","    b_fc = tf.get_variable('b', shape=[num_features], initializer=tf.zeros_initializer)\n","    fc = tf.matmul(input_flattened, W_fc) + b_fc\n","    return(fc)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZdFbl0QMdLK_","colab_type":"code","colab":{}},"cell_type":"code","source":["#tf.reset_default_graph()\n","\n","def create_network(scale):\n","    pool_ksize = [1,2,2,1]\n","    pool_strides = [1,2,2,1]\n","    # The network:\n","    with tf.variable_scope(\"conv1\"):\n","            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n","            relu1 = conv_relu_layer(x_image, filter_size=[5, 5],num_features=32*scale)\n","            pool1 = tf.nn.max_pool(relu1, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n","    with tf.variable_scope(\"conv2\"):\n","            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n","            relu2 = conv_relu_layer(pool1, filter_size=[5, 5],num_features=64*scale)\n","            pool2 = tf.nn.max_pool(relu2, ksize=pool_ksize, strides=pool_strides, padding='SAME')\n","    with tf.variable_scope('dropout2'):\n","            drop2=tf.nn.dropout(pool2,keep_prob)\n","    with tf.variable_scope(\"fc1\"):\n","            fc1 = fully_connected_layer(drop2, num_features=128*scale)\n","            fc1r=tf.nn.relu(fc1)\n","   \n","    with tf.variable_scope(\"fc2\"):\n","            fc2 = fully_connected_layer(fc1r, num_features=51)\n","\n","    # Names (OUT,LOSS, ACC) below added to make it easier to use this tensor when restoring model\n","    fc2 = tf.identity(fc2, name=\"OUT\")\n","    # The loss computation\n","    with tf.variable_scope('cross_entropy_loss'):\n","        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=fc2),name=\"LOSS\")\n","\n","    # Accuracy computation\n","    with tf.variable_scope('helpers'):\n","        correct_prediction = tf.equal(tf.argmax(fc2, 1), tf.argmax(y_, 1))\n","        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float16), name=\"ACC\")\n","    # We return the final functions (they contain all the information about the graph of the network)\n","    return cross_entropy, accuracy, fc2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y2aEE7kCdxgO","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get loss and accuracy on a data set with output from final layer fc2\n","\n","from scipy.special import logsumexp\n","\n","def get_stats(data,labels):\n","    t1 = time.time()\n","    loss = 0.\n","    acc = 0.\n","    delta = 1000\n","    rr = np.arange(0, data.shape[0], delta)\n","    for i in rr:\n","        fc2_out = fc2.eval(feed_dict={x: data[i:i + delta], y_:labels[i:i + delta]})\n","        log_sf = logsumexp(fc2_out, axis=1).reshape((fc2_out.shape[0], 1)) - fc2_out\n","        loss += np.mean(np.sum(labels[i:i+delta] * log_sf, axis=1))\n","        acc += np.mean(np.equal(np.argmax(fc2_out, axis=1),np.argmax(labels[i:i+delta], axis=1)))\n","    acc = acc/np.float32(len(rr))\n","    loss = loss/np.float32(len(rr))\n","    print('Stats time:', time.time()-t1)\n","    # We return the final functions (they contain all the information about the graph of the network)\n","    return loss, acc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wOrIgC-6frjc","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run the iterations of one epoch\n","def run_epoch(tdata, tlabels, ii, batch_size, train_step_new):\n","  t1 = time.time()\n","  # Randomly shuffle the training data\n","  np.random.shuffle(ii)\n","  tr = tdata[ii]\n","  y = tlabels[ii]\n","  loss = 0.\n","  acc = 0.\n","  # Run disjoint batches on shuffled data\n","  for j in np.arange(0, len(y), batch_size):\n","    if (np.mod(j, 5000) == 0):\n","      print('Batch', j/batch_size)\n","    batch =(tr[j:j+batch_size], y[j:j+batch_size])\n","    train_step_new.run(feed_dict={x: batch[0], y_: batch[1], lr_: step_size, keep_prob_:keep_prob})\n","  print('Epoch Time:', time.time() - t1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-2uywstXgtaA","colab_type":"code","outputId":"336ed76c-3d64-484e-8ef3-184356e491cb","executionInfo":{"status":"error","timestamp":1544645782486,"user_tz":360,"elapsed":53709,"user":{"displayName":"Anand Kannappan","photoUrl":"https://lh5.googleusercontent.com/-RBaeYAFRI9g/AAAAAAAAAAI/AAAAAAAAAHA/dDIr1dAXiyM/s64/photo.jpg","userId":"04884028647086034831"}},"colab":{"base_uri":"https://localhost:8080/","height":4501}},"cell_type":"code","source":["print(train_data.shape)\n","\n","# Run the training\n","\n","import time\n","batch_size = 100\n","step_size = 0.001\n","num_epochs = 15\n","num_train = 1000\n","minimizer = \"Adam\"\n","model_name = \"model1\"\n","keep_prob = 0.5\n","dim1 = 128\n","dim2 = 128\n","nchannels = 1\n","\n","tf.reset_default_graph()\n","\n","x = tf.placeholder(tf.float32, shape=[None, dim1*dim2*nchannels], name=\"x\")\n","x_image = tf.reshape(x, [-1, dim1, dim2, nchannels])\n","# Dimensions of x_image: [Batch size, Column size, Row size, Number of incoming channels]\n","# The number of incoming channels, for example, will be 3 if the image is color: RGB (red, green, blue)\n","# We will slide filter over this 2d picture with conv2d function.\n","y_ = tf.placeholder(tf.float32, shape=[None,51], name=\"y\")\n","# Allows you to control the time step during the iterations\n","lr_ = tf.placeholder(tf.float32, shape=[], name=\"learning_rate\")\n","keep_prob_=tf.placeholder(tf.float32, shape=[], name=\"keep_prob\")\n","\n","with tf.Session() as sess:\n","        # Create the network architecture with the above placeholdes as the inputs.\n","        cross_entropy, accuracy, fc2 = create_network(1)\n","\n","        # Define the miminization method\n","        if (minimizer==\"Adam\"):\n","            train_step = tf.train.AdamOptimizer(learning_rate=lr_).minimize(cross_entropy)\n","        elif (minimizer==\"SGD\"):\n","            train_step = tf.train.GradientDescentOptimizer(learning_rate=lr_).minimize(cross_entropy)\n","        # Initialize variables\n","        sess.run(tf.global_variables_initializer())\n","#         # Show trainable variables\n","#         total_parameters = 0\n","#         for v in tf.trainable_variables():\n","#             print(v.name, v.get_shape().as_list(), np.std(v.eval()))\n","#             shape = v.get_shape()\n","#             var_parameters = 1\n","#             for dim1 in shape:\n","#                 var_parameters = var_parameters * dim1.value\n","#             total_parameters += var_parameters\n","        ii = np.arange(0, num_train, 1) \n","        # Run epochs\n","        train_error_original = []\n","        validation_error_original = []\n","        for i in range(num_epochs):  # number of epochs\n","            run_epoch(train_data, train_labels, ii, batch_size, train_step)\n","            loss, acc = get_stats(train_data[0:num_train], train_labels[0:num_train])\n","            train_error_original.append(1 - acc)\n","            print('Epoch:', i,'Train loss:', loss, 'Accuracy:', acc)\n","            vloss, vacc = get_stats(val_data, val_labels)\n","            validation_error_original.append(1 - vacc)\n","            print('Epoch',i,'Validation loss', vloss, 'Accuracy', vacc)\n","\n","        print('Test Accuracy %g' % accuracy.eval(feed_dict={x: test_data, y_:test_labels}))\n","\n","        # Save model\n","        tf.add_to_collection(\"optimizer\", train_step)\n","        saver = tf.train.Saver()\n","        save_path = saver.save(sess, \"drive/My Drive/Computer Vision/saved_models/\" + model_name)\n","        print(\"Model saved in path: %s\" % save_path)\n","#        print(\"Total number of parameters: %s\" % total_parameters)\n","\n","        conv1_W = sess.run(tf.trainable_variables()[0])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(27548, 16384)\n","Batch 0.0\n","Epoch Time: 1.3319659233093262\n","Stats time: 0.4272782802581787\n","Epoch: 0 Train loss: 3.891650438308716 Accuracy: 0.067\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.256178855895996\n","Epoch 0 Validation loss 3.926836371421814 Accuracy 0.029098360655737707\n","Batch 0.0\n","Epoch Time: 1.1228604316711426\n","Stats time: 0.40561628341674805\n","Epoch: 1 Train loss: 3.701124429702759 Accuracy: 0.121\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.2454485893249512\n","Epoch 1 Validation loss 3.9135794043540955 Accuracy 0.07434016393442623\n","Batch 0.0\n","Epoch Time: 1.1268043518066406\n","Stats time: 0.40770649909973145\n","Epoch: 2 Train loss: 3.0321288108825684 Accuracy: 0.356\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.251471757888794\n","Epoch 2 Validation loss 3.9772589802742004 Accuracy 0.058991803278688526\n","Batch 0.0\n","Epoch Time: 1.1244468688964844\n","Stats time: 0.4053189754486084\n","Epoch: 3 Train loss: 1.6537258625030518 Accuracy: 0.65\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.260957956314087\n","Epoch 3 Validation loss 4.671637177467346 Accuracy 0.05169672131147541\n","Batch 0.0\n","Epoch Time: 1.1355416774749756\n","Stats time: 0.4083132743835449\n","Epoch: 4 Train loss: 0.5919241905212402 Accuracy: 0.851\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.264711856842041\n","Epoch 4 Validation loss 7.000490427017212 Accuracy 0.06204508196721312\n","Batch 0.0\n","Epoch Time: 1.126509189605713\n","Stats time: 0.4048607349395752\n","Epoch: 5 Train loss: 0.22024114429950714 Accuracy: 0.946\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.2564046382904053\n","Epoch 5 Validation loss 9.028183221817017 Accuracy 0.07199180327868852\n","Batch 0.0\n","Epoch Time: 1.1250696182250977\n","Stats time: 0.4118080139160156\n","Epoch: 6 Train loss: 0.12148485332727432 Accuracy: 0.975\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.263362169265747\n","Epoch 6 Validation loss 10.903753280639648 Accuracy 0.06394672131147541\n","Batch 0.0\n","Epoch Time: 1.122924566268921\n","Stats time: 0.4065980911254883\n","Epoch: 7 Train loss: 0.0851207748055458 Accuracy: 0.982\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.2586398124694824\n","Epoch 7 Validation loss 10.185502529144287 Accuracy 0.06964344262295083\n","Batch 0.0\n","Epoch Time: 1.1232292652130127\n","Stats time: 0.40495729446411133\n","Epoch: 8 Train loss: 0.056856419891119 Accuracy: 0.986\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.2474455833435059\n","Epoch 8 Validation loss 10.891658544540405 Accuracy 0.07054508196721311\n","Batch 0.0\n","Epoch Time: 1.1244709491729736\n","Stats time: 0.4071502685546875\n","Epoch: 9 Train loss: 0.0401664674282074 Accuracy: 0.989\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.2635838985443115\n","Epoch 9 Validation loss 11.468988180160522 Accuracy 0.07339344262295082\n","Batch 0.0\n","Epoch Time: 1.1280176639556885\n","Stats time: 0.40823984146118164\n","Epoch: 10 Train loss: 0.053805120289325714 Accuracy: 0.988\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.260035514831543\n","Epoch 10 Validation loss 12.431130409240723 Accuracy 0.07254508196721311\n","Batch 0.0\n","Epoch Time: 1.123171091079712\n","Stats time: 0.406064510345459\n","Epoch: 11 Train loss: 0.04357307776808739 Accuracy: 0.99\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.2633397579193115\n","Epoch 11 Validation loss 12.200304746627808 Accuracy 0.07939344262295082\n","Batch 0.0\n","Epoch Time: 1.1245551109313965\n","Stats time: 0.4092895984649658\n","Epoch: 12 Train loss: 0.029764449223876 Accuracy: 0.996\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.2584154605865479\n","Epoch 12 Validation loss 10.986692667007446 Accuracy 0.08259016393442623\n","Batch 0.0\n","Epoch Time: 1.1250250339508057\n","Stats time: 0.40572357177734375\n","Epoch: 13 Train loss: 0.023730235174298286 Accuracy: 0.994\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.256749153137207\n","Epoch 13 Validation loss 12.851062059402466 Accuracy 0.07289344262295082\n","Batch 0.0\n","Epoch Time: 1.1239964962005615\n","Stats time: 0.4088864326477051\n","Epoch: 14 Train loss: 0.020044522359967232 Accuracy: 0.995\n","[ 0.     0.     0.    ... 12.1    6.688  1.875] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n","Stats time: 1.2592616081237793\n","Epoch 14 Validation loss 13.668349981307983 Accuracy 0.07314344262295083\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3401,32,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv1/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1/W/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-3d423a9f9b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Validation loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvacc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Accuracy %g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5155\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5156\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5157\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3401,32,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv1/Conv2D (defined at <ipython-input-4-5598902f613a>:6)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1/W/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv1/Conv2D', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-3d423a9f9b3e>\", line 31, in <module>\n    cross_entropy, accuracy, fc2 = create_network(1)\n  File \"<ipython-input-6-83d93352aab2>\", line 8, in create_network\n    relu1 = conv_relu_layer(x_image, filter_size=[5, 5],num_features=32*scale)\n  File \"<ipython-input-4-5598902f613a>\", line 6, in conv_relu_layer\n    conv = tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 957, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3401,32,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv1/Conv2D (defined at <ipython-input-4-5598902f613a>:6)  = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, conv1/W/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"]}]},{"metadata":{"id":"80MbU_Sg5gpR","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vBMxtxanlnox","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":297},"outputId":"3206826d-b591-44bf-d2a4-861d4d8a0673","executionInfo":{"status":"ok","timestamp":1544644442662,"user_tz":360,"elapsed":60785,"user":{"displayName":"Anand Kannappan","photoUrl":"https://lh5.googleusercontent.com/-RBaeYAFRI9g/AAAAAAAAAAI/AAAAAAAAAHA/dDIr1dAXiyM/s64/photo.jpg","userId":"04884028647086034831"}}},"cell_type":"code","source":["plt.plot(range(num_epochs), train_error_original)\n","plt.title(\"Error Rate on Training Data by Epoch\")"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5,1,'Error Rate on Training Data by Epoch')"]},"metadata":{"tags":[]},"execution_count":10},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXIAAAEHCAYAAACzy817AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmYXHWZ9vFvLd2dXpPqpEN2OpDw\nZAFJwhpZQ0BcQRzEbeRlhFFHRp190NddR0dnlBF1RvR1nxEUGRBcIazBsMYAQsIDgeydpZN00umk\n00t1v3+c06Fo0t3V66nTfX+uK1dOnTpVdae6c9evfnXqnERnZyciIhJfyagDiIjI4KjIRURiTkUu\nIhJzKnIRkZhTkYuIxJyKXEQk5tJRBxjrzKwTeBFo73bVle7+2DA+7g+BNwF7wlUpYCfw9+7+aB+3\nLQHe4e4/Hq58PTzuHcAJXRd5+XlrdPfT+3E/04Hfu/uJfWz3Y+AWd79zgJFz76sW2AA4wQCqFFgF\nfMbd1+Vx+4uBde6+uR+P+RlghrtfM8DM5wN3AS91v87d5w3kPnt5rFpgvburkwZAT1phON/dt0bw\nuF939y90XTCzK4BbgRl93G4xcCUwokXu7pd0LYcvgAN63tx9G9BriYfbXdnf++5DtqsAzSwFvB94\n0MzOdnfv47Z/C3wByLvIh8jmoS5tGXoq8gIWjlJWAT8Dlrj7eWGBfRy4ClgALAT+C5gIHAb+2d1/\nH46mvghsBdrc/T15POQvgZ+ZWY2715vZNcDfE/yebAfeGz7GbUCVma1093PM7CzgP4AMsBt4t7u/\nahQXZvoaUAbsB6519yfM7CqCdweNwDkEo+y3u/uz/Xi6MLONwPeB9wAXEYx6vxc+N0XAJ939ptzR\nX2+PbWb3A//P3f87fN6vBP4OmAJ8xd2vN7Mk8HXg7cB64E7gDe5+fm9Z3T0L/Ff47uDTwLvN7Bjg\nR0AtUAJ8w92/ZmafB5YD883sn8LH+AGwCCgGbnX3f+jhoSrN7FcEvyebgHcAl4cZ3xw+b0mCn+/F\n7v5kr09yjnDEXwtMAk4i+F27zN13mdks4Lvh9W3h8/Xj8HZXAp8I7+ZR4Jqc+3wf8DcEv0v/5O43\n5ZtnLNMceeGbBDzp7uflrEu4uwGdwM3AN8NR0zXATWZWGW63GPh2PiVuZgngQ8DzwG4zmwx8E7jI\n3ecSlNQn3X0n8DHg4bDEKwmK5ePuPoeg1H5+lPuvAG4BPhxm/Qrw07BEAN4I/Ke7nwDcR/CfeSBm\nuLuFUxD/DvzK3ecD7wO+Z2ZFR7lNvo+90N0XA5cAXwxH1W8E3gDMCddf1c+8dwDLwuVPABvC52c5\n8CUzm+nunwS2Ae9x958BfwVUAvOAJcBVZnZ2D/f/BuAj7j6boGivI/g5XGBmE8NtzgIa+lPiOd5G\n8DM9lmAK5mPh+u8A94e/p28CbjCz2vBF9N+B8wmmx8qBj4S3SQLF7v4aXn4HInlQkReG+83suZw/\nK3OuKyIYAef6Vfj3bILR4c0A7v4EwajrtPD6Zne/t5fH/WjXYwIHCf5zvdHdO919F1CVM3WxEjju\nKPdxDrDV3e8OM9wEzAlHZLnOCLf7Q7jdrQQvUrXh9WvdfXW4/Eeg++3z9auc5UuBfwuXHwLGAVOP\ncpt8H/snOduMAyYT/Pt/5e5N7r4X6O8IshEYHy5/BPgwQPiOZgfBz/gV3P2rwKXhz6kBeJaj/2wA\nHsp5d3QLsDT82a4kGJkDXEbwru9oZnX73XzOzL6ac/197r4hXP5f4LXhi+VFwH+GeTcRvEBeALwO\nWOXude7eCbwbuD68fYKXp+vW0PcUn4Q0tVIYepvrzbp7Y7d1e8O/a4B94X+ILg0EBbMjZ7ueHJkj\nN7ObCKYbXgwvp4DPmdklBB+EVhKM1rubABwfvhh0aQmz5c7n1oTZcu0Ls0Iw1dIlGz7mQOT+my8G\nPmFmNUAHQVEcbfCS72Pvh2BaxMwIt8sQjHS7bOtn3lpgV7h8GsEofFaYY+rR8prZXOBrZjYv3G4m\nwVTL0dR3y58Jl28C/gK4keAF7y093L6vOfLc57shvP+JBO8a93e7bnL479nXtdLdD4f/Jgh+1w+F\nVw3md2DM0Yg83nYC1eG0SJeJ4fr++hTwkXDOFoK51EuAc8O3x5/u4XZ1BHtTzMv5c0zOCDc3a9db\n+a6pnOoBZu1TOCq8BfiXcMrkZIKpqKHWCFTkXD7aiL83lxPsGQLw38AvgBPC8qzv4TbfAp4B5oXb\n9TYlUp2znOHl4r0NONXM3ggccve1/czdZVK3x9pL8DlJh5llcq7r+r3cnXsbM6sKPxuQQVCRx9tG\ngtHgOwDM7LUEUy393m3R3V8geHvdNS85Gdjo7rvDudQreLmw2gg+7EwQfFg11czOCDMcZ2Y/6fbi\nQphpipktDS+/M8y+sb9Z81Qe/nkivPxRoJVXlu5QeAx4s5mVmtkEguepT2aWMrMPEYyE/yVcPRlY\n7e6dZvZ/CPLnPucTcrZbE74zuAiYS8//rrNzprkuJ5hSIRwt/45g+qOnaZV8nG1mM3Pv393bgd8D\nHwj/rccD5wIrgN8AZ4Xz5Qng28DVg3h8QVMrheJ+M+u+H/k3eeV876uE/+HfCXzbzD5NMM/9dnc/\nGL5V7a/PAW5m/0Hw1vtdZrae4EOsTwB3hPOjNwBfJhiNzyD4D/yN8IPPVoIPRV8x+g0zXQF808zK\nCUab7wz/DQPJ2it332dmXwHWmNkugheo2wme0zcN4UPdBryZYP/wFwg+6F3ew7apnCmoCQQvgueG\nc8gAnwRuM7M9BFMeNwLfDT/I/AVws5l9Kvy3XB8u3w58lmAabE3XZxA57iD42ZxEsB/7R3Ouu4ng\nw8reinxWt2mzLl27Zt4NfMvMFhN8PtP1weUHw+xXEfxOXOPuWwDM7P3AvQTTJ48R7Mk0pZcM0oeE\njkcuMjhmluh64TKza4EL3f2yiGP1ycxOJ9jjKe8vU3W7/WcYxBeOZOhoRC4yCGa2CLg9HJEeIBjh\n/j7aVH0zszTB5yI3RJ1FBk9z5CKDEO57/SNgNbCOYK+Vb0Yaqg/hi86LBFNj/xNxHBkCmloREYk5\njchFRGJuxOfI6+sPDPgtQCZTRkPDob43LBBxyhunrBCvvHHKCvHKG6esMLi8NTWV3XfpPSJWI/J0\nOl5f9IpT3jhlhXjljVNWiFfeOGWF4csbqyIXEZFXU5GLiMScilxEJOZU5CIiMaciFxGJORW5iEjM\nqchFRGIuNkW+t/Ew37/zWbbVN0UdRUSkoMTm6Iebdh7gtvvXc/sDcN6i6bz17NlUlRdHHUtEJHKx\nGZEvmjOJT119Bsdkyrh/zTY+9p2H+e0jm2hr74g6mohIpGIzIk8kEpy2YAozqkt54Mk6bl/5Erfc\n/yL3rdnG25fN4VSrIZHo8VAEIiKjVmyKvEs6lWT5KTM4c+Ex3PmHjdyzeiv/dfszzJkxnnctn8vs\nqVVRRxQRGVGxmVrprnxcEe9cPpcvXHMGS06oYf3W/Xz+R0/w3TufZW/j4ajjiYiMmNiNyLs7prqM\nv37bSTy3qYGb732Bh5/dyWqv5+LTZ/GGM2cxrjj2/0QRkV7FdkTe3bxjM3zqqtN43xvnUzouzZ2r\nNvKx7zzCyqfr6OjQWZBEZPQaNUUOkEwkOPs1U/nX9y/lkrNqaT7czg9+8xyf++HjPLepIep4IiLD\nYlQVeZeS4hRvPec4vvj+M1m6cAqbdzXxlZvW8I1bn2bn3vicTUREJB+jegK5umocf/mWBVx46gxu\nvucF1rywm6df3MMFS2Zwydm1lI8rijqiiMigjcoReXezp1Zx3XuW8KG3nkimsoS7n9jCdd9+mLuf\n2EJ7Vl8oEpF4GxNFDsEXik6dN5l/+cszuWLZHDo6O7lpxQt88nuP8cyGPVHHExEZsDFT5F2K0kle\nf8YsvvSBpSxbPJ1dDYf4+i1Ps2e/9j0XkXgac0XepaqsmPdebFz1+nlkOzq5d83WqCOJiAzImC3y\nLmcuPIbKsiIefLKOlrZs1HFERPptzBd5UTrF+Yumc/BwO488uyPqOCIi/Tbmixzg/MXTSSUTrHhi\nK52d+haoiMSLihzIVJZw2rzJbNt9UN8AFZHYUZGHlp86A4C7n9CHniISLyry0PHTxnPctCqeWr+b\nXfuao44jIpI3FXmOC0+ZQSdw72qNykUkPlTkOU6dN5nxFcWsfLqOw63tUccREcmLijxHOpVk2eLp\nNLdk+cOftCuiiMRDXkc/NLPrgTOBTuCj7v54znXXAn8OZIEn3P1vhiPoSDlv0XR+tSo4F+iyJdNJ\n6oTOIlLg+hyRm9l5wFx3XwpcDdyQc10V8I/AOe5+NrDAzM4crrAjYXx5MWfMP4Ydew/x7Ia9UccR\nEelTPlMry4HbAdx9HZAJCxygNfxTYWZpoAyIfftdeOpMAFZoV0QRiYF8plamAKtzLteH6xrd/bCZ\nfRZ4CWgGbnb353u7s0ymjHQ6NdC81NRUDvi2/XmMBbOr+dNLe2glwfSaikHdV1zEKSvEK2+cskK8\n8sYpKwxP3oGcIejIpHE4Mv84cALQCNxrZie7+1M93bihYeCnWqupqaS+/sCAb98f5508jbUb9nLL\nXc57XnfCgO5jJPMOVpyyQrzyxikrxCtvnLLC4PL29gKQz9RKHcEIvMs0YHu4PB94yd13u3srsBI4\nZUApC8ySEyaRqSzhoWe2c+iwdkUUkcKVT5HfBVwOYGZLgDp373pJ2QjMN7PS8PKpwAtDHTIKqWSS\nC5ZMp6U1y0N/2t73DUREItJnkbv7KmC1ma0i2GPlWjO7yswuc/edwL8B95nZQ8Aad185vJFHznmL\nplOUTnLP6i10dOioiCJSmPKaI3f367qteirnuhuBG4cyVKGoKC1i6cJjePCp7Tz94h4WzZ0UdSQR\nkVfRNzv7cOEp4a6Iq7dEnERE5OhU5H2YMbmCebMmsHZjA9vqm6KOIyLyKiryPHR9QegeHRVRRAqQ\nijwPi+ZMYtL4cax6ZgdNzW1RxxEReQUVeR6SyQQXLJlBa3sHK5+uizqOiMgrqMjzdO7JUykuSnLv\n6q1kOzqijiMicoSKPE9l44o468Sp7Gls4ckXdkcdR0TkCBV5Pyw/RSdoFpHCoyLvh2mTylk4u5rn\nt+xj8874HKhHREY3FXk/XRiOyldoV0QRKRAq8n466fiJTM6U8sizO2k81Bp1HBERFXl/JRMJlp8y\ng/ZsBw8+qV0RRSR6KvIBOPukqYwrTnHfmm20Z7UroohES0U+AKUlac4+aSoNB1r44/P1UccRkTFO\nRT5Ay0+dQQK4+wkdFVFEoqUiH6BjMmWcdPxEXtzWyIbtjVHHEZExTEU+CBeFR0VcoVG5iERIRT4I\nC2ozTJ1YxmPrdrG/qSXqOCIyRqnIByGRSHDhqTPJdnRy35ptUccRkTFKRT5Ir104hdKSNPc/WUdb\nu3ZFFJGRpyIfpJLiFOeePJXGg608/tzOqOOIyBikIh8Cy5fMIJEIjorY2dkZdRwRGWNU5ENg0oRS\nFs2ZxKYdB3hxm3ZFFJGRpSIfIkd2RVytXRFFZGSpyIeIzZrAjJoKnniunr2Nh6OOIyJjiIp8iAS7\nIs6go1O7IorIyFKRD6EzFxxDRWkRDzxZR2tbNuo4IjJGqMiHUHFRivMWTaOpuY1H12pXRBEZGSry\nIbZs8XSSiQQrVmtXRBEZGSryIVZdNY4lVsOWXU0889KeqOOIyBigIh8GF50anKD51w9tiDiJiIwF\nKvJhMGf6eI7JlPJH36VTwYnIsFORD4NEIsGC2dU0t7TrpBMiMuxU5MNkYW01AM9u2BtxEhEZ7dL5\nbGRm1wNnAp3AR9398ZzrZgI3AcXAH939g8MRNG7mzcqQTMDajQ289Zyo04jIaNbniNzMzgPmuvtS\n4Grghm6bfBX4qrufDmTNbNbQx4yfsnFp5s7K8FJdI80t7VHHEZFRLJ+pleXA7QDuvg7ImFkVgJkl\ngXOAO8Lrr3X3zcOUNXYWnVBDR2cnz21uiDqKiIxi+UytTAFW51yuD9c1AjXAAeB6M1sCrHT3j/V2\nZ5lMGel0aoBxoaamcsC3HWmLT5jMz+5+ng07mnjda4+LOk6f4vTcQrzyxikrxCtvnLLC8OTNa468\nm0S35enA14GNwK/N7E3u/uuebtzQcGgADxmoqamkvv7AgG8/0uzYDCXFKZ5Yt5O3FXjuuD23ccob\np6wQr7xxygqDy9vbC0A+Uyt1BCPwLtOA7eHybmCTu7/o7lngHmDhgFKOQulUEps5gR17D+nQtiIy\nbPIp8ruAywHC6ZM6dz8A4O7twEtmNjfc9hTAhyNoXB3ZDXGjdkMUkeHRZ5G7+ypgtZmtIthj5Voz\nu8rMLgs3+RvgB+H1+4E7hy1tDC2YHRT52o36wFNEhkdec+Tufl23VU/lXLceOHsoQ40m0yaWMaGi\nmLUb99LR2Ukykej7RiIi/aBvdg6zRCLBgtpqDhxqY+uupqjjiMgopCIfAV3z5JpeEZHhoCIfAQtq\nM4A+8BSR4aEiHwHjK0qYXlPO81v20dauc3mKyNBSkY+QhbXVtLV3sH7r/qijiMgooyIfIQuO7E+u\neXIRGVoq8hFiMyeQSiY0Ty4iQ05FPkJKilPMmT6ezTsO0NTcFnUcERlFVOQjaMHsajqBdZs0vSIi\nQ0dFPoJ0+jcRGQ4q8hFUO6WSspI0azfupbOzM+o4IjJKqMhHUDKZYP6xGXbvP8yufc1RxxGRUUJF\nPsJ0NEQRGWoq8hG2MPy6/lrNk4vIEFGRj7DJmTImjR/Huk0NdHRonlxEBk9FHoEFtdUcamlnw47G\nqKOIyCigIo/AQs2Ti8gQUpFHYP6xGRJonlxEhoaKPAIVpUXMmlLJ+m37OdzaHnUcEYk5FXlEFtZW\nk+3o5PktOqytiAyOijwiR3ZD1NEQRWSQVOQRmTNjPMXppA5rKyKDpiKPSFE6xdyZE9hWf5B9TS1R\nxxGRGFORR6jraIjrtBuiiAyCijxCC8J5ck2viMhgqMgjNGNyBVVlRTyrw9qKyCCoyCOUTCSYX1vN\n/qZW6nYfjDqOiMSUijxiC47shqh5chEZGBV5xI6c/k3z5CIyQCryiFVXjWPqxDJ88z7asx1RxxGR\nGFKRF4AFx1bT0pblxW36ur6I9J+KvAAsmK15chEZOBV5AZg3K0MykdBxV0RkQFTkBaC0JM1x06t4\naXsjhw63RR1HRGImryI3s+vN7GEzW2Vmp/WwzZfM7P4hTTeGLDg2Q2cnrNu0L+ooIhIzfRa5mZ0H\nzHX3pcDVwA1H2WYBcO7Qxxs7jpz+bZOmV0Skf/IZkS8Hbgdw93VAxsyqum3zVeD/DnG2MWX21CrG\nFad0+jcR6bd0HttMAVbnXK4P1zUCmNlVwAPAxnweMJMpI51O9StkrpqaygHfNgr9yfuaOTU8tnYH\nnakUk6vLhjHV0Y3m5zZqccoK8cobp6wwPHnzKfLuEl0LZlYN/AVwITA9nxs3NBwawEMGamoqqa8/\nMODbj7T+5p0zrZLH1u5g5R+3cO7J04Yx2auN9uc2SnHKCvHKG6esMLi8vb0A5DO1UkcwAu8yDdge\nLl8A1AArgduAJWZ2/YBSysvz5NoNUUT6IZ8ivwu4HMDMlgB17n4AwN1/4e4L3P1M4DLgj+7+t8OW\ndpSbUl1GprKEtRsb6NBhbUUkT30WubuvAlab2SqCPVauNbOrzOyyYU83xiQSCRbUZmhqbmPLzqao\n44hITOQ1R+7u13Vb9dRRttkInD/4SGPbwtpq/vCnHazduJdjp8TrQxwRiYa+2VlgFuiwtiLSTyry\nAlNVXszMyRU8v2U/rW3ZqOOISAyoyAvQgtoM7dkOXtiqw9qKSN9U5AWo66xB2g1RRPKhIi9Ac2dO\nIJ1KaJ5cRPKiIi9AJUUp5s6YwOadTTQeao06jogUOBV5gVpQG5w1aJ3OGiQifVCRF6gFmicXkTyp\nyAvUscdUUj4uzdqNe+nU1/VFpBcq8gKVTCaYX1vNnsYWdjY0Rx1HRAqYiryAdc2TP6uTTYhIL1Tk\nBUz7k4tIPlTkBaxmQimTJ5Ty3OYGsh0dUccRkQKlIi9wC2ozNLdk2bA9PmdBEZGRpSIvcEd2Q9Q8\nuYj0QEVe4ObXZkgkNE8uIj1TkRe48nFF1E6p4sW6Rppb2qOOIyIFSEUeAwtqM2Q7OvEt+6KOIiIF\nSEUeAws1Ty4ivVCRx8Dx08dTXJRk7SYdQEtEXk1FHgNF6SQ2M0Pd7oM0HGiJOo6IFBgVeUx0fV1f\ne6+ISHcq8pjomifXWYNEpDsVeUxMrylnfHkxazc26LC2IvIKKvKYSCQSLKjN0HiwlW31B6OOIyIF\nREUeI11f11+zfnfESUSkkKjIY+TkOZMoK0nzu0c366TMInKEijxGKkqLuPSc2TS3tHP7gy9FHUdE\nCoSKPGaWLZ7OtEnlPPBkHZt36tC2IqIij510Ksm7ls+lE/jpihe0B4uIqMjjaOHsahbPncTzW/bx\n+HO7oo4jIhFTkcfUOy6YQzqV4Jb71tPSlo06johESEUeU5MzZbzutFnsaWzhd49ujjqOiERIRR5j\nb1p6LOMrivntI5vYs/9w1HFEJCLpfDYys+uBM4FO4KPu/njOdcuALwFZwIFr3F2nfB8BpSVpLj/v\neL7363Xccv96PnjpiVFHEpEI9DkiN7PzgLnuvhS4Grih2ybfAS5397OASuD1Q55SerT0xCkcN62K\nx9btwjfreOUiY1E+UyvLgdsB3H0dkDGzqpzrT3H3reFyPTBxaCNKb5KJBO+6cC4AN614gY4O7Y4o\nMtbkM7UyBVidc7k+XNcI4O6NAGY2FXgd8Mne7iyTKSOdTg0oLEBNTeWAbxuFkchbU1PJBafu4t4n\ntrDmpb28fmntgO8nTuKUN05ZIV5545QVhidvXnPk3SS6rzCzycCdwIfcfU9vN25oODSAhwzU1FRS\nXx+fbzOOZN43nzmLPzxdx49+vZb5M6ooG1fUr9vruR0+ccoK8cobp6wwuLy9vQDkM7VSRzAC7zIN\n2N51IZxm+S3wCXe/a0AJZdAmVJTwltfW0tTcxi8f2hh1HBEZQfkU+V3A5QBmtgSoc/fcl5SvAte7\n+++GIZ/0w0WnzmTyhFLu/eNW6nbrmOUiY0WfRe7uq4DVZraKYI+Va83sKjO7zMzKgCuBa8zs/vDP\n+4c5s/SgKJ3kHcvnkO3o5OZ7dBwWkbEirzlyd7+u26qncpZLhi6ODNaiOZNYWJvhmQ17eerFPSya\nMynqSCIyzPTNzlEmkUjwzgtPIJlIcPM9L9DWru9miYx2KvJRaPqkci5YMp1dDc2sWL0l6jgiMsxU\n5KPUpefMpqK0iDv/sJH9TS1RxxGRYaQiH6XKxxVx2bnHcbg1y60P6LRwIqOZinwUO+/kacycXMFD\nf9rOhu2NUccRkWGiIh/FkskE7w6Pw/LTu5+nQ7sjioxKKvJRzmZlOHXeZF6sa+TRZ3dGHUdEhoGK\nfAy4YtnxFKWT3HL/eg63tkcdR0SGmIp8DJg0vpQ3nDGLfU2t/PrhTVHHEZEhpiIfI95w5rFkKkv4\n/WNb2LWvOeo4IjKEVORjRElRiiuWzaE928HP710fdRwRGUIq8jHk9PmTmTtjPH98vp61G/dGHUdE\nhoiKfAxJJBK8+8ITSBCcFi7boeOwiIwGKvIx5tgplZxz8jS27T7I/Wvqoo4jIkNART4Gve3c4ygt\nSXP7ypdoam6LOo6IDJKKfAyqKi/m0rNqOXi4ndtW6jgsInGnIh+jLjhlBlOqy7h/zTa27mqKOo6I\nDIKKfIxKp5K868K5dHbCT1c8r9PCicSYinwMO+m4iZx8/ESe27yPVX/aHnUcERkgFfkY987lc0kl\nE3z/jmdoOKATUIjEkYp8jDumuoyLT5/FroZmrrvxYX5+33rtySISMypy4W3nHseHr1hEZVkRv3t0\nM//87VXc8YcNNLfoSIkicZCOOoBEL5lM8LozjuXEWeO5b00dv1q1kdtXbuCe1Vt509Jali2eRlE6\nFXVMEemBRuRyRFE6xetOm8mXP7iUt54zm/ZsBzff8wLX3fgIDz5Vp6/0ixQoFbm8SmlJmkvOms2X\nP/haXn/GLJqa2/jhb5/jE999lMfW7dQp40QKjIpcelRRWsQVy+bwrx9YyrLF09m9/zDf/uWzfPYH\nj/PU+t3a91ykQGiOXPqUqSzhvRcbF58+k18+tIFHnt3J13/xNHNmjOfPzj0Om5WJOqLImKYRueRt\ncqaMv3zLQj579eksnjuJ9Vv38+WfruFrP3uSTTsORB1PZMzSiFz6bUZNBR/+s9fwYt1+/veBl3hm\nw16e2bCXU62Gy849jqkTy6OOKDKmqMhlwI6fNp5/fNdi1m7cy60PvMQTXs/q5+s568SpXHJ2LZPG\nl0YdUWRMUJHLoC2orWb+sRnWvLCb2x58iYf+tJ1H1u7g/EXTuei0mWQqS0inNIsnMlxU5DIkEokE\nS06oYdGcSTyydge3r9zAitVbWbF6KxDsAVNVXkxVWdffxcHfXX/KiqkqL2J8ebG+fCTSTypyGVLJ\nZILXnjiV0+cfw0NPb2fdpgYaD7bSeKiV/U0t1O0+2Od9lJakXi76Hgq/OdtJ88EWxhWnKClOkUpq\nxC9jl4pchkU6leT8xdM5f/H0V6xvz3Zw4FAbjQdb2X+w9UjJv+Lvg600Hmpj17795LurelE6ybji\nVFDsRWnGlQTL44pSjCtOHyn8YJv0kW3HFadfXl+UIplMDPlzkShK09TcRklRknQqSSIx9I8RpY6O\nTvYfbKXhQAsNBw6z90BLuNxCQ2NwufFgKyQglUySSiZIpRKkk4ngcioRrHvFcoJUKvmK5fRRtptQ\nVUpRAiZUljC+vJgJlSVMKC+muGhsvavLq8jN7HrgTKAT+Ki7P55z3YXAF4Es8Bt3//xwBJXRIZ1K\nkqksIVNZ0ue2HR2dNDWHpX+olQNhye8/1EpnIsm+xmYOt2Q53NpOS1uWw63Bn6bmwxxubc/7RWAk\nJRJQXJSiJJ2kuCgV/DmynKSkKEVxOkVJ0cvrgsvhcs71RekkRekURemg5IrSSYpSXeuTpFJJkoN8\n0WjPdrCv6eVi3tvYcqSwGw7MQyiCAAAHFklEQVS0sPdAC/ubWnv8tm8CGF9RHOzJlIBstpNsRwfZ\njk6y2U5a27NkWzvD9eF12U4G+6MrLUkzoaKYCRUlTKgoZnxFUPBHCr+ihAkVJZQUj47C77PIzew8\nYK67LzWz+cD3gaU5m9wAXAxsAx4ws1vdfe2wpJUxJZlMHJlSmdHtupqaSurre953vbOzk9b2Dlpa\ng6LvKvnD4eWWnOXDrVkOt2Vpac0Oy7dVi4rTHGhqobW9g9a2LK1tHbS2Z2lty9J4sDVY1z48x7FJ\npxKkc8q9a/nIum5/p1NJ2js72bH7IA3hSLqnZySVTDChooTjpldRXRkUY3VlCZmqcWQqg+Wq8uIB\nfdDd0dFJezYs/I5OsuFye85yNttJaXkJm7btY19T8IIS/N3CvoOt7DvQwvY9h3p9nHHFqVeWfUUx\n48tLKB+XDkf9L7+D6HonkD7au4Xu7yK6vXsY7AtqX/IZkS8Hbgdw93VmljGzKndvNLPjgL3uvgXA\nzH4Tbq8il0glEglKioKRbFV5caRZ+nrRAejo7KQtp+hb2rJh2QfrWsLyb2l7eV1re5b29k7ash20\ntXfQHv6du3xkXfh3S1uWg81tRy739LpVlA7eOdnECUwI30FVV4478m6qurKEyvLiYSuoZDJBcbLv\n0XJNTSWTK3v++ba1d7D/YAv7moLPaPYdKftW9h1sYd+BVvYfbGHH3t4Lf7ASieA5fd+bF3K61Qz5\n/edT5FOA1TmX68N1jeHf9TnX7QKO7+3OMpky0oPYK6GmpnLAt41CnPLGKSvEK2+hZs1mO2ht73oB\nyNLW3kHZuCIqy4piM5ff13M7LY/7aGvvYF84ZbRn/2EOHW6jPZwGas8G0z1d7xByL/d2XffLHZ2d\nTJxQOiy/CwP5sLO3n26fP/mGhoG/8uUzsikkccobp6wQr7xxypoCqsqLY5N3qJ/bTGmaTGnFkN1f\nd4PJ29sLQD6TV3UEI+8u04DtPVw3PVwnIiIjJJ8ivwu4HMDMlgB17n4AwN03AlVmVmtmaeDN4fYi\nIjJC+pxacfdVZrbazFYBHcC1ZnYVsN/dbwP+Crgp3Pxn7v78sKUVEZFXyWuO3N2v67bqqZzrHuSV\nuyOKiMgI0veaRURiTkUuIhJzKnIRkZhTkYuIxFxCZ0IXEYk3jchFRGJORS4iEnMqchGRmFORi4jE\nnIpcRCTmVOQiIjGnIhcRibmBnFgiEr2dALoQmdlXgHMInuMvufv/RhypV2ZWCjwDfN7dfxhxnF6Z\n2XuAfwLagU+5+68jjnRUZlYB/BjIACXAZ93999GmejUzOxH4JXC9u3/TzGYCPyE4z8R24L3u3hJl\nxi49ZP0BUAS0AX/u7juizJire96c9RcDv3P3ITkNUyxG5LkngAauJjjhc8Eys2XAiWHe1wP/EXGk\nfHwC2Bt1iL6Y2UTg08DZBMe/vzTaRL26CnB3X0ZwTP+vRxvn1cysHPgGcE/O6s8B33L3c4D1wPui\nyNZdD1m/AHzH3c8DbgP+LopsR9NDXsxsHPAxXj5Bz6DFosjpdgJoIGNmVdFG6tWDwNvD5X1AuZkN\n/ESlw8zM5gELgIIc2XZzIbDC3Q+4+3Z3f3/UgXqxG5gYLmfCy4WmBXgjrzyz1/nAHeHynQTPeSE4\nWtYPAbeGy/W8/HwXgqPlBfg48C2gdageKC5F3v0kz10ngC5I7p5194PhxauB37h7NspMffgqBTSS\n6UMtUGZmd5jZSjNbHnWgnrj7zcAsM1tP8OL+DxFHehV3b3f35m6ry3OmUnYBU0c41lEdLau7H3T3\nbDhQuhb4aTTpXu1oec3sBOBkd79lKB8rLkXeXSxO721mlxIU+V9HnaUnZnYl8LC7b4g6S54SBKOu\ntxFMXfzAzAry98HM/hzY7O5zgAuAb/Zxk0JUkM9trrDEfwLc6+739LV9xK5nGAZNcSny3k4AXZDC\nDzP+L/AGd98fdZ5evAm41MweAa4BPmlmhfJW+mh2AqvC0c6LwAGgJuJMPTkL+D2Auz8FTCvkKbYc\nTeGH3xCPE6r/AHjB3T8bdZDemNl0YB7wP+H/t6lm9sBQ3Hdc9lq5C/gscGP3E0AXIjMbD/wbcKG7\nF/QHiO7+jq5lM/sMsNHdV0SXqE93AT80sy8TzDtXUJhzzxB8UHgGcKuZHQs0FfgUW5cVwJ8B/x3+\n/bto4/Qs3IOp1d0/HXWWvrj7NuD4rstmtjH8kHbQYlHkRzsBdNSZ+vAOYBLwczPrWnelu2+OLtLo\n4O7bzOwXwCPhqg+7e0eUmXpxI/D9cNSVBj4YcZ5XMbNTCD4jqQXazOxy4D0EL5YfADYBP4ou4ct6\nyDoZOGxm94ebrXX3D0WT8JV6yPu24Rjc6XjkIiIxF5c5chER6YGKXEQk5lTkIiIxpyIXEYk5FbmI\nSMypyEVEYk5FLiISc/8fYiORwRUYpB8AAAAASUVORK5CYII=\n","text/plain":["<matplotlib.figure.Figure at 0x7fc4aba50ef0>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"-OhaRHF3MTXO","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}